{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageTranlationEngtoHin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4b/UoDOD6BvdKbRngAMU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apyarn95/LanguageTranslationEngToHin/blob/main/LanguageTranlationEngtoHin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c7uJhEg5B8k"
      },
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import digits\n",
        "import re ,os,io,time\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGtq8Vew5rYw",
        "outputId": "51b4a95d-b680-4dbf-e5b7-0f5e4bb4fb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#mounting the content to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcV7LNku5ciz"
      },
      "source": [
        "#loading dataset from drive\n",
        "data = pd.read_csv('/content/gdrive/My Drive/HindiEnglish.csv',encoding='utf-8')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vDpHXM88AsV"
      },
      "source": [
        "new_data = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_nWd-qK8rGb"
      },
      "source": [
        "#defining contraction mapping to change all the occurences of short form to their original meaning \n",
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTO6eVWF82El"
      },
      "source": [
        "#defining preprocessing stuff\n",
        "def preprocess_sent(w):\n",
        "  w = w.lower().strip()\n",
        "  w = ' '.join(contraction_mapping[t] if t in contraction_mapping else t for t in w.split(\" \"))\n",
        "  \n",
        "  #removing everything within brackets\n",
        "  w = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", w)\n",
        "  #creating space between word and punctuation following\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "  #replace everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "  w = ' '.join(t for t in w.split(\" \") if t != \" \")\n",
        "  w = w.strip()\n",
        "  \n",
        "  #inclusind <sostoken> and <eostoken> to identify starting and ending of the sentences\n",
        "  w = '<sostoken> ' + w + ' <eostoken>'\n",
        "  return w\n",
        "\n",
        "def preprocess_hindi_sent(w):\n",
        "  w = w.strip()\n",
        "  remove_num = str.maketrans('','',digits)\n",
        "  w = w.translate(remove_num)\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "  w = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", w)\n",
        "  w = w.strip()\n",
        "  \n",
        "  w = '<sostoken> ' + w + ' <eostoken>' \n",
        "  return w\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSDRLf9vdGjP"
      },
      "source": [
        "new_data = data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q18n0QRe-IOj"
      },
      "source": [
        "for x in range(len(new_data)):\n",
        "  if x not in new_data['english_sentence'].keys():\n",
        "    continue\n",
        "  new_data['english_sentence'][x] = preprocess_sent(str(new_data['english_sentence'][x]))\n",
        "  new_data['hindi_sentence'][x] = preprocess_hindi_sent(str(new_data['hindi_sentence'][x]))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dZmcsP6VQAM"
      },
      "source": [
        "#calculating lenght of the sentences\n",
        "new_data['eng_len'] = new_data['english_sentence'].apply(lambda x : len(x.split(\" \")))\n",
        "new_data['hin_len'] = new_data['hindi_sentence'].apply(lambda x : len(x.split(\" \")))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLExxaCsVR5i"
      },
      "source": [
        "#removing all intstances where lenght<=25 to reduce dataset for faster computations\n",
        "sent_max_len = 25\n",
        "new_data = new_data[new_data['eng_len'] <= sent_max_len]\n",
        "new_data = new_data[new_data['hin_len'] <= sent_max_len]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tIU0PHwLigu",
        "outputId": "0e95914b-a4a6-4a3c-f5a3-85e2908c6ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#removing null values or duplicates dataset\n",
        "new_data = new_data[~pd.isnull(data['english_sentence'])]\n",
        "new_data.drop_duplicates(inplace=True)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYVGL8Z0cL9j",
        "outputId": "b740ab15-6668-4840-b1c1-d09c07ac69fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(new_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtQHwCFMBJBd"
      },
      "source": [
        "#converting pandas core series datastructrure to list for further calculations as tensors in tensorflow\n",
        "english_sentences = new_data['english_sentence'].tolist()\n",
        "hindi_sentences = new_data['hindi_sentence'].tolist() "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKEKSCkaRYNt"
      },
      "source": [
        "\n",
        "#tokenizing the sentences (changing each sentence to a vector of numbers describing the sentence)\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esK9__s1S7LB"
      },
      "source": [
        "#input_tensor and target_tensor contains vectors representing each sentence where every word has a unique index or token\n",
        "#to access the word_index we can use inp_lang_tokenizer.word_index where (word) -> (key) type mapping would be there\n",
        "input_tensor , inp_lang_tokenizer = tokenize(english_sentences)\n",
        "target_tensor , targ_lang_tokenize = tokenize(hindi_sentences)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4SuyZZkBp-G"
      },
      "source": [
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuAEA9-1HBA-"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL9-nfpHUI0K"
      },
      "source": [
        "#defining the model runtime attributes\n",
        "#units -> number of gated GRU cells\n",
        "#vocab_inp_size is the total size of the english vocab (number of unique words in the corpus) \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 300\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenize.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g5dFjIbWbtx",
        "outputId": "5480cd2c-4f95-486f-f891-cf12e74a0f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#example_input_batch and example_target batch are the batch iterators that would feed data = batch size from the training to the corpus\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 25]), TensorShape([64, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_MBkLryW4sv"
      },
      "source": [
        "#defining the encoder class\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I7IfE6bW9Pw",
        "outputId": "439a9714-d02d-471c-d5b5-4fc097ff093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#definine the encoder layer with the above defined params\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 25, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCRQS_QaXLzx"
      },
      "source": [
        "#for attention we would use Bahdanau attention layer for more information read readme.md file\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsbUqm7gXO2w",
        "outputId": "5be46298-763b-4a2e-9fec-e88fa15debf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 25, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqpUsFuNXW8i"
      },
      "source": [
        "#decoder definition\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKMTIKsXcNh",
        "outputId": "f974a2e9-2fa5-4bbe-8872-0b4e646457b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 47825)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUSqCpgWXjUb"
      },
      "source": [
        "#defining optimizers and loss function\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G66rHQpEXlgM"
      },
      "source": [
        "\n",
        "checkpoint_prefix = \"/content/gdrive/My Drive/LanguageTranslation.ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkTjyDBYEUa"
      },
      "source": [
        "#training the model\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenize.word_index['<sostoken>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1M7pjVPYIRU",
        "outputId": "94f833d7-1af7-4669-e0ac-d4ba97ecb6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.9836\n",
            "Epoch 1 Batch 100 Loss 3.1134\n",
            "Epoch 1 Batch 200 Loss 3.6906\n",
            "Epoch 1 Batch 300 Loss 3.1655\n",
            "Epoch 1 Batch 400 Loss 3.2391\n",
            "Epoch 1 Batch 500 Loss 3.3576\n",
            "Epoch 1 Batch 600 Loss 2.6207\n",
            "Epoch 1 Batch 700 Loss 3.1969\n",
            "Epoch 1 Batch 800 Loss 3.0094\n",
            "Epoch 1 Batch 900 Loss 2.7789\n",
            "Epoch 1 Batch 1000 Loss 2.8313\n",
            "Epoch 1 Batch 1100 Loss 2.6783\n",
            "Epoch 1 Loss 3.1486\n",
            "Time taken for 1 epoch 494.08093309402466 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.9995\n",
            "Epoch 2 Batch 100 Loss 2.7091\n",
            "Epoch 2 Batch 200 Loss 2.6454\n",
            "Epoch 2 Batch 300 Loss 2.6420\n",
            "Epoch 2 Batch 400 Loss 2.6788\n",
            "Epoch 2 Batch 500 Loss 2.8468\n",
            "Epoch 2 Batch 600 Loss 2.4967\n",
            "Epoch 2 Batch 700 Loss 2.6480\n",
            "Epoch 2 Batch 800 Loss 2.8598\n",
            "Epoch 2 Batch 900 Loss 2.6732\n",
            "Epoch 2 Batch 1000 Loss 2.6031\n",
            "Epoch 2 Batch 1100 Loss 2.4562\n",
            "Epoch 2 Loss 2.7003\n",
            "Time taken for 1 epoch 470.745352268219 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.4701\n",
            "Epoch 3 Batch 100 Loss 2.3665\n",
            "Epoch 3 Batch 200 Loss 2.5536\n",
            "Epoch 3 Batch 300 Loss 2.2051\n",
            "Epoch 3 Batch 400 Loss 2.2951\n",
            "Epoch 3 Batch 500 Loss 2.3008\n",
            "Epoch 3 Batch 600 Loss 2.2563\n",
            "Epoch 3 Batch 700 Loss 2.3507\n",
            "Epoch 3 Batch 800 Loss 2.3975\n",
            "Epoch 3 Batch 900 Loss 2.5190\n",
            "Epoch 3 Batch 1000 Loss 2.2973\n",
            "Epoch 3 Batch 1100 Loss 2.4101\n",
            "Epoch 3 Loss 2.4460\n",
            "Time taken for 1 epoch 468.0245883464813 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.1882\n",
            "Epoch 4 Batch 100 Loss 2.2410\n",
            "Epoch 4 Batch 200 Loss 2.1947\n",
            "Epoch 4 Batch 300 Loss 2.2295\n",
            "Epoch 4 Batch 400 Loss 2.0619\n",
            "Epoch 4 Batch 500 Loss 1.8535\n",
            "Epoch 4 Batch 600 Loss 2.1522\n",
            "Epoch 4 Batch 700 Loss 1.9930\n",
            "Epoch 4 Batch 800 Loss 1.7921\n",
            "Epoch 4 Batch 900 Loss 1.9409\n",
            "Epoch 4 Batch 1000 Loss 1.9438\n",
            "Epoch 4 Batch 1100 Loss 1.7809\n",
            "Epoch 4 Loss 2.0597\n",
            "Time taken for 1 epoch 475.4034962654114 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.7304\n",
            "Epoch 5 Batch 100 Loss 1.5978\n",
            "Epoch 5 Batch 200 Loss 1.7427\n",
            "Epoch 5 Batch 300 Loss 1.5928\n",
            "Epoch 5 Batch 400 Loss 1.5490\n",
            "Epoch 5 Batch 500 Loss 1.3800\n",
            "Epoch 5 Batch 600 Loss 1.4955\n",
            "Epoch 5 Batch 700 Loss 1.5502\n",
            "Epoch 5 Batch 800 Loss 1.6437\n",
            "Epoch 5 Batch 900 Loss 1.4333\n",
            "Epoch 5 Batch 1000 Loss 1.5840\n",
            "Epoch 5 Batch 1100 Loss 1.7134\n",
            "Epoch 5 Loss 1.5690\n",
            "Time taken for 1 epoch 470.5969364643097 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.3040\n",
            "Epoch 6 Batch 100 Loss 0.9469\n",
            "Epoch 6 Batch 200 Loss 1.0163\n",
            "Epoch 6 Batch 300 Loss 1.0621\n",
            "Epoch 6 Batch 400 Loss 1.2750\n",
            "Epoch 6 Batch 500 Loss 1.2289\n",
            "Epoch 6 Batch 600 Loss 1.2238\n",
            "Epoch 6 Batch 700 Loss 1.3467\n",
            "Epoch 6 Batch 800 Loss 1.1193\n",
            "Epoch 6 Batch 900 Loss 1.0406\n",
            "Epoch 6 Batch 1000 Loss 1.1785\n",
            "Epoch 6 Batch 1100 Loss 1.2686\n",
            "Epoch 6 Loss 1.1674\n",
            "Time taken for 1 epoch 475.87301325798035 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.8869\n",
            "Epoch 7 Batch 100 Loss 0.7957\n",
            "Epoch 7 Batch 200 Loss 0.8378\n",
            "Epoch 7 Batch 300 Loss 0.7813\n",
            "Epoch 7 Batch 400 Loss 0.7762\n",
            "Epoch 7 Batch 500 Loss 0.8716\n",
            "Epoch 7 Batch 600 Loss 0.7210\n",
            "Epoch 7 Batch 700 Loss 0.8382\n",
            "Epoch 7 Batch 800 Loss 0.8228\n",
            "Epoch 7 Batch 900 Loss 0.8834\n",
            "Epoch 7 Batch 1000 Loss 0.8543\n",
            "Epoch 7 Batch 1100 Loss 0.8558\n",
            "Epoch 7 Loss 0.8635\n",
            "Time taken for 1 epoch 472.7938117980957 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5741\n",
            "Epoch 8 Batch 100 Loss 0.5773\n",
            "Epoch 8 Batch 200 Loss 0.4615\n",
            "Epoch 8 Batch 300 Loss 0.6487\n",
            "Epoch 8 Batch 400 Loss 0.7731\n",
            "Epoch 8 Batch 500 Loss 0.7555\n",
            "Epoch 8 Batch 600 Loss 0.7476\n",
            "Epoch 8 Batch 700 Loss 0.7351\n",
            "Epoch 8 Batch 800 Loss 0.6999\n",
            "Epoch 8 Batch 900 Loss 0.5385\n",
            "Epoch 8 Batch 1000 Loss 0.6124\n",
            "Epoch 8 Batch 1100 Loss 0.7029\n",
            "Epoch 8 Loss 0.6534\n",
            "Time taken for 1 epoch 474.5387990474701 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4198\n",
            "Epoch 9 Batch 100 Loss 0.4271\n",
            "Epoch 9 Batch 200 Loss 0.4362\n",
            "Epoch 9 Batch 300 Loss 0.4200\n",
            "Epoch 9 Batch 400 Loss 0.4513\n",
            "Epoch 9 Batch 500 Loss 0.4763\n",
            "Epoch 9 Batch 600 Loss 0.5212\n",
            "Epoch 9 Batch 700 Loss 0.5692\n",
            "Epoch 9 Batch 800 Loss 0.4691\n",
            "Epoch 9 Batch 900 Loss 0.5893\n",
            "Epoch 9 Batch 1000 Loss 0.5145\n",
            "Epoch 9 Batch 1100 Loss 0.4508\n",
            "Epoch 9 Loss 0.4975\n",
            "Time taken for 1 epoch 471.56304931640625 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.3487\n",
            "Epoch 10 Batch 100 Loss 0.3712\n",
            "Epoch 10 Batch 200 Loss 0.3237\n",
            "Epoch 10 Batch 300 Loss 0.3396\n",
            "Epoch 10 Batch 400 Loss 0.3068\n",
            "Epoch 10 Batch 500 Loss 0.3454\n",
            "Epoch 10 Batch 600 Loss 0.3527\n",
            "Epoch 10 Batch 700 Loss 0.2966\n",
            "Epoch 10 Batch 800 Loss 0.3473\n",
            "Epoch 10 Batch 900 Loss 0.3464\n",
            "Epoch 10 Batch 1000 Loss 0.3701\n",
            "Epoch 10 Batch 1100 Loss 0.4210\n",
            "Epoch 10 Loss 0.3816\n",
            "Time taken for 1 epoch 477.0939111709595 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.2203\n",
            "Epoch 11 Batch 100 Loss 0.2880\n",
            "Epoch 11 Batch 200 Loss 0.2278\n",
            "Epoch 11 Batch 300 Loss 0.3071\n",
            "Epoch 11 Batch 400 Loss 0.2957\n",
            "Epoch 11 Batch 500 Loss 0.3497\n",
            "Epoch 11 Batch 600 Loss 0.2644\n",
            "Epoch 11 Batch 700 Loss 0.3160\n",
            "Epoch 11 Batch 800 Loss 0.3474\n",
            "Epoch 11 Batch 900 Loss 0.2651\n",
            "Epoch 11 Batch 1000 Loss 0.3166\n",
            "Epoch 11 Batch 1100 Loss 0.2724\n",
            "Epoch 11 Loss 0.2957\n",
            "Time taken for 1 epoch 471.2049307823181 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.1516\n",
            "Epoch 12 Batch 100 Loss 0.1609\n",
            "Epoch 12 Batch 200 Loss 0.2138\n",
            "Epoch 12 Batch 300 Loss 0.2241\n",
            "Epoch 12 Batch 400 Loss 0.2088\n",
            "Epoch 12 Batch 500 Loss 0.2139\n",
            "Epoch 12 Batch 600 Loss 0.1842\n",
            "Epoch 12 Batch 700 Loss 0.2618\n",
            "Epoch 12 Batch 800 Loss 0.2378\n",
            "Epoch 12 Batch 900 Loss 0.2726\n",
            "Epoch 12 Batch 1000 Loss 0.2397\n",
            "Epoch 12 Batch 1100 Loss 0.2813\n",
            "Epoch 12 Loss 0.2299\n",
            "Time taken for 1 epoch 473.08761191368103 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.1970\n",
            "Epoch 13 Batch 100 Loss 0.1225\n",
            "Epoch 13 Batch 200 Loss 0.1565\n",
            "Epoch 13 Batch 300 Loss 0.1425\n",
            "Epoch 13 Batch 400 Loss 0.2005\n",
            "Epoch 13 Batch 500 Loss 0.1836\n",
            "Epoch 13 Batch 600 Loss 0.2118\n",
            "Epoch 13 Batch 700 Loss 0.2354\n",
            "Epoch 13 Batch 800 Loss 0.2070\n",
            "Epoch 13 Batch 900 Loss 0.2640\n",
            "Epoch 13 Batch 1000 Loss 0.1817\n",
            "Epoch 13 Batch 1100 Loss 0.2096\n",
            "Epoch 13 Loss 0.1854\n",
            "Time taken for 1 epoch 468.35178542137146 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1289\n",
            "Epoch 14 Batch 100 Loss 0.1209\n",
            "Epoch 14 Batch 200 Loss 0.1608\n",
            "Epoch 14 Batch 300 Loss 0.1413\n",
            "Epoch 14 Batch 400 Loss 0.1545\n",
            "Epoch 14 Batch 500 Loss 0.1809\n",
            "Epoch 14 Batch 600 Loss 0.1317\n",
            "Epoch 14 Batch 700 Loss 0.1427\n",
            "Epoch 14 Batch 800 Loss 0.1401\n",
            "Epoch 14 Batch 900 Loss 0.1498\n",
            "Epoch 14 Batch 1000 Loss 0.1852\n",
            "Epoch 14 Batch 1100 Loss 0.1377\n",
            "Epoch 14 Loss 0.1542\n",
            "Time taken for 1 epoch 465.6646785736084 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.1356\n",
            "Epoch 15 Batch 100 Loss 0.1213\n",
            "Epoch 15 Batch 200 Loss 0.1100\n",
            "Epoch 15 Batch 300 Loss 0.1084\n",
            "Epoch 15 Batch 400 Loss 0.1012\n",
            "Epoch 15 Batch 500 Loss 0.1233\n",
            "Epoch 15 Batch 600 Loss 0.1378\n",
            "Epoch 15 Batch 700 Loss 0.0983\n",
            "Epoch 15 Batch 800 Loss 0.1568\n",
            "Epoch 15 Batch 900 Loss 0.1416\n",
            "Epoch 15 Batch 1000 Loss 0.1500\n",
            "Epoch 15 Batch 1100 Loss 0.1467\n",
            "Epoch 15 Loss 0.1302\n",
            "Time taken for 1 epoch 460.08196568489075 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0853\n",
            "Epoch 16 Batch 100 Loss 0.1187\n",
            "Epoch 16 Batch 200 Loss 0.0889\n",
            "Epoch 16 Batch 300 Loss 0.1199\n",
            "Epoch 16 Batch 400 Loss 0.1011\n",
            "Epoch 16 Batch 500 Loss 0.0923\n",
            "Epoch 16 Batch 600 Loss 0.0922\n",
            "Epoch 16 Batch 700 Loss 0.1401\n",
            "Epoch 16 Batch 800 Loss 0.1351\n",
            "Epoch 16 Batch 900 Loss 0.1057\n",
            "Epoch 16 Batch 1000 Loss 0.1381\n",
            "Epoch 16 Batch 1100 Loss 0.1253\n",
            "Epoch 16 Loss 0.1120\n",
            "Time taken for 1 epoch 463.69669675827026 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0823\n",
            "Epoch 17 Batch 100 Loss 0.0587\n",
            "Epoch 17 Batch 200 Loss 0.1248\n",
            "Epoch 17 Batch 300 Loss 0.0867\n",
            "Epoch 17 Batch 400 Loss 0.1181\n",
            "Epoch 17 Batch 500 Loss 0.0860\n",
            "Epoch 17 Batch 600 Loss 0.0875\n",
            "Epoch 17 Batch 700 Loss 0.1070\n",
            "Epoch 17 Batch 800 Loss 0.0897\n",
            "Epoch 17 Batch 900 Loss 0.0975\n",
            "Epoch 17 Batch 1000 Loss 0.1101\n",
            "Epoch 17 Batch 1100 Loss 0.0948\n",
            "Epoch 17 Loss 0.1008\n",
            "Time taken for 1 epoch 459.75782895088196 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0953\n",
            "Epoch 18 Batch 100 Loss 0.0904\n",
            "Epoch 18 Batch 200 Loss 0.0917\n",
            "Epoch 18 Batch 300 Loss 0.0647\n",
            "Epoch 18 Batch 400 Loss 0.0850\n",
            "Epoch 18 Batch 500 Loss 0.0785\n",
            "Epoch 18 Batch 600 Loss 0.0958\n",
            "Epoch 18 Batch 700 Loss 0.0779\n",
            "Epoch 18 Batch 800 Loss 0.0811\n",
            "Epoch 18 Batch 900 Loss 0.1095\n",
            "Epoch 18 Batch 1000 Loss 0.1039\n",
            "Epoch 18 Batch 1100 Loss 0.1280\n",
            "Epoch 18 Loss 0.0918\n",
            "Time taken for 1 epoch 465.17282247543335 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0690\n",
            "Epoch 19 Batch 100 Loss 0.0783\n",
            "Epoch 19 Batch 200 Loss 0.0565\n",
            "Epoch 19 Batch 300 Loss 0.0666\n",
            "Epoch 19 Batch 400 Loss 0.0609\n",
            "Epoch 19 Batch 500 Loss 0.0745\n",
            "Epoch 19 Batch 600 Loss 0.0745\n",
            "Epoch 19 Batch 700 Loss 0.0578\n",
            "Epoch 19 Batch 800 Loss 0.0836\n",
            "Epoch 19 Batch 900 Loss 0.0640\n",
            "Epoch 19 Batch 1000 Loss 0.1054\n",
            "Epoch 19 Batch 1100 Loss 0.0868\n",
            "Epoch 19 Loss 0.0829\n",
            "Time taken for 1 epoch 463.4125180244446 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0847\n",
            "Epoch 20 Batch 100 Loss 0.0719\n",
            "Epoch 20 Batch 200 Loss 0.0611\n",
            "Epoch 20 Batch 300 Loss 0.0550\n",
            "Epoch 20 Batch 400 Loss 0.0642\n",
            "Epoch 20 Batch 500 Loss 0.0843\n",
            "Epoch 20 Batch 600 Loss 0.0876\n",
            "Epoch 20 Batch 700 Loss 0.0847\n",
            "Epoch 20 Batch 800 Loss 0.0842\n",
            "Epoch 20 Batch 900 Loss 0.0755\n",
            "Epoch 20 Batch 1000 Loss 0.0995\n",
            "Epoch 20 Batch 1100 Loss 0.1031\n",
            "Epoch 20 Loss 0.0796\n",
            "Time taken for 1 epoch 464.07613015174866 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdrz7Ssg2n7-",
        "outputId": "fc376faf-de37-4518-ff98-446530281f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# save the model\n",
        "checkpoint.save(file_prefix = '/content/gdrive/My Drive/Translate.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Translate.ckpt-12'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4H4ZC2uCoCm"
      },
      "source": [
        "#cconvert the english sentence to hindi using the model\n",
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sent(sentence)\n",
        "\n",
        "  inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang_tokenize.word_index['<sostoken>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang_tokenize.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang_tokenize.index_word[predicted_id] == '<eostoken>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE-3MNeP2kSC"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  print('Predicted translation: {}'.format(result))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngx1fGbcA3pP"
      },
      "source": [
        "#example dataset\n",
        "print('Input : %s ' %(data['english_sentence'][0]))\n",
        "print('Original translation : %s ' %(data['hindi_sentence'][0]))\n",
        "print(translate(data['english_sentence'][0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}